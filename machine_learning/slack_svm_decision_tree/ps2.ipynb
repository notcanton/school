{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem Set 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADENsiDx12vR"
      },
      "outputs": [],
      "source": [
        "# Boiler plate\n",
        "\n",
        "import cvxopt\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "park_train_path = \"./park_train.data\"\n",
        "park_validation_path = \"./park_validation.data\"\n",
        "park_test_path = \"./park_test.data\"\n",
        "mush_train_path = \"./mush_train.data\"\n",
        "mush_test_path = \"./mush_test.data\"\n",
        "wdbc_train_path = \"./wdbc_train.data\"\n",
        "wdbc_test_path = \"./wdbc_test.data\"\n",
        "\n",
        "cvxopt.solvers.options['show_progress'] = False\n",
        "\n",
        "park_train = np.genfromtxt(park_train_path, delimiter=',')\n",
        "park_val = np.genfromtxt(park_validation_path, delimiter=',')\n",
        "park_test = np.genfromtxt(park_test_path, delimiter=\",\")\n",
        "mush_test = np.genfromtxt(mush_test_path, delimiter=',', dtype=np.character)\n",
        "mush_train = np.genfromtxt(mush_train_path, delimiter=\",\", dtype=np.character)\n",
        "wdbc_train = np.genfromtxt(wdbc_train_path, delimiter=\",\")\n",
        "wdbc_test = np.genfromtxt(wdbc_test_path, delimiter=\",\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb0SSMCXf8dR"
      },
      "source": [
        "# Problem 1 : Parkinsonâ€™s Disease"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_NYPajZgKj3"
      },
      "source": [
        "## 1. Primal SVMs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6mJBPDvoC4P"
      },
      "source": [
        "Primal Problem\n",
        "\n",
        "$$ \\min_{w, b, \\xi} \\frac{1}{2} ||w||^2 + c \\sum_i \\xi_i $$\n",
        "such that \n",
        "$$ y_i(w^T w^{(i)} + b) \\geq 1 - \\xi_i, \\forall i$$\n",
        "$$ \\xi_i \\geq 0, \\forall i$$\n",
        "\n",
        "CVXOPT Formulation\n",
        "\n",
        "$$\\min \\frac{1}{2} z^T P z + q^T z $$\n",
        "subject to\n",
        "$$ Gz \\leq h $$\n",
        "\n",
        "Let $z = [w_1, ..., w_m, b, \\xi_1, ..., \\xi_m]$ \n",
        "\n",
        "---\n",
        "\n",
        "Objective Function \n",
        "\n",
        "We isolate the $w$ variables by having $P$ be a zero matrix with 1's along the diagonal where the index corresponds to a w value.\n",
        "$$P_{i,i} = 1 \\text{ if } z_i = w_i$$\n",
        "\n",
        "For $c \\sum_i \\xi_i$, we let the $q$ vector have $c$ in all indices that corresponds to a $\\xi$ value else it will be zero.\n",
        "$$q_{i} = c \\text{ if } z_i = \\xi_i$$\n",
        "\n",
        "---\n",
        "\n",
        "Inequality Constraint\n",
        "\n",
        "The $G$ matrix will be split into two halves representing each constraint in the primal problem. \n",
        "\n",
        "For the upper half, $y_i(w^T w^{(i)} + b) \\geq 1 - \\xi_i$ can be rewritten as:\n",
        "\n",
        "$$ -y_i(w^T w^{(i)} + b) - \\xi_i \\leq -1 $$\n",
        "\n",
        "This can be converted similarly to the hard margin formulation. The only change is there will be trailing 0's in each\n",
        "row for $\\xi$ values not corresponding to the current data point index and a $-1$ for the correct data point index.\n",
        "\n",
        "$$ G_i = [-x_jy, ..., -x_my, -by, 0, ..., -1, 0, ...]$$\n",
        "\n",
        "For the lower half, it would be a zero matrix with a $-1$ for the corresponding $\\xi$ in the $z$ vector\n",
        "\n",
        "$$ G_j = [0, ..., -1^{j}, 0, ...]$$\n",
        "where\n",
        "$$ z_j = \\xi_j$$\n",
        "\n",
        "The $h$ vector will have $-1$ for the first $m$ entries (corresponding to the first inequality constraint) and 0 for the next\n",
        "$m$ entries.\n",
        "\n",
        "$$ h = [-1,...,0,...]$$\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2RpOEmb8gWfi"
      },
      "source": [
        "### Apply the SVM with slack formulation for each choice of $c \\in \\{10^{-4}, 10^{-3}, ..., 10^3, 10^4\\}$ without using any feature maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j98YtNzLg2ne"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LinearSlackSVM():\n",
        "    def __init__(self):\n",
        "        self.w = 0\n",
        "        self.b = 0\n",
        "    def fit(self, X, y, c):\n",
        "        num_data = X.shape[0] # num of data points\n",
        "        dim_data = X.shape[1]\n",
        "\n",
        "        # Compute P\n",
        "        P = np.identity(dim_data + 1 + num_data)\n",
        "        for i in range(dim_data, dim_data + 1 + num_data):\n",
        "            P[i, i] = 0\n",
        "        P = cvxopt.matrix(P)\n",
        "\n",
        "        # Compute q\n",
        "        q = np.zeros(dim_data + 1 + num_data)\n",
        "        for i in range(dim_data + 1, dim_data + 1 + num_data):\n",
        "            q[i] = c\n",
        "        q = cvxopt.matrix(q)\n",
        "\n",
        "        # Compute G\n",
        "        G = np.zeros((2 * num_data, dim_data + 1 + num_data))\n",
        "        for i, row in enumerate(X):\n",
        "            slack = np.zeros(num_data)\n",
        "            slack[i] = -1\n",
        "            temp = np.append(-y[i] * row[:], -y[i])\n",
        "            temp = np.append(temp, slack)\n",
        "            G[i] = temp\n",
        "\n",
        "        for i in range(num_data):\n",
        "            temp = np.zeros(dim_data + 1 + num_data)\n",
        "            temp[i + dim_data + 1] = -1\n",
        "            G[i + num_data] = temp\n",
        "        G = cvxopt.matrix(G)\n",
        "\n",
        "        # Compute h\n",
        "        h = cvxopt.matrix(np.append(-np.ones(num_data), np.zeros(num_data)))\n",
        "\n",
        "        solution = cvxopt.solvers.qp(P, q, G, h)\n",
        "        \n",
        "        w = np.array(solution['x']).flatten()[:dim_data]\n",
        "        b = np.array(solution['x']).flatten()[dim_data]\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "\n",
        "        return (w, b)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.sign(np.dot(X, self.w) + self.b)\n",
        "\n",
        "    def accuracy(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        correct = np.equal(y, y_pred)\n",
        "        return np.count_nonzero(correct) / len(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rAl48mwng1KS"
      },
      "source": [
        "### What is the accuracy for each value of $c$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDH7OciEhE13",
        "outputId": "9a3424aa-9c27-4ac0-be30-be77e2aaac3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c = 0.001,\ttrain acc = 0.8589743589743589\n",
            "c = 0.01,\ttrain acc = 0.8461538461538461\n",
            "c = 0.1,\ttrain acc = 0.8974358974358975\n",
            "c = 1.0,\ttrain acc = 0.8846153846153846\n",
            "c = 10.0,\ttrain acc = 0.8846153846153846\n",
            "c = 100.0,\ttrain acc = 0.8846153846153846\n",
            "c = 1000.0,\ttrain acc = 0.8974358974358975\n",
            "c = 10000.0,\ttrain acc = 0.8846153846153846\n",
            "c = 100000.0,\ttrain acc = 0.8974358974358975\n"
          ]
        }
      ],
      "source": [
        "c_values = [10e-4, 10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3, 10e4]\n",
        "\n",
        "X_train = park_train[:,1:]\n",
        "y_train = park_train[:,0]\n",
        "y_train[y_train == 0] = -1\n",
        "\n",
        "X_val = park_val[:,1:]\n",
        "y_val = park_val[:,0]\n",
        "y_val[y_val == 0] = -1\n",
        "\n",
        "X_test = park_test[:,1:]\n",
        "y_test = park_test[:,0]\n",
        "y_test[y_test == 0] = -1\n",
        "\n",
        "\n",
        "model = LinearSlackSVM()\n",
        "\n",
        "for c in c_values:\n",
        "    model.fit(X_train, y_train, c)\n",
        "    train_acc = model.accuracy(X_train, y_train)\n",
        "    print(f\"c = {c},\\ttrain acc = {train_acc}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LNPwLgYkhFSS"
      },
      "source": [
        "### What is the accuracy on the validation set for each value of $c$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POAK1R8WhL8K",
        "outputId": "610aad39-1142-4e3a-ef2d-4bdf9175e782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c = 0.001,\tval_acc = 0.8448275862068966\n",
            "c = 0.01,\tval_acc = 0.7758620689655172\n",
            "c = 0.1,\tval_acc = 0.8103448275862069\n",
            "c = 1.0,\tval_acc = 0.8620689655172413\n",
            "c = 10.0,\tval_acc = 0.8620689655172413\n",
            "c = 100.0,\tval_acc = 0.8620689655172413\n",
            "c = 1000.0,\tval_acc = 0.8103448275862069\n",
            "c = 10000.0,\tval_acc = 0.8103448275862069\n",
            "c = 100000.0,\tval_acc = 0.8448275862068966\n",
            "Validation, best c = 1.0, acc = 0.8620689655172413\n"
          ]
        }
      ],
      "source": [
        "model = LinearSlackSVM()\n",
        "best_c = None\n",
        "best_acc = 0\n",
        "\n",
        "for c in c_values:\n",
        "    model.fit(X_train, y_train, c)\n",
        "    val_acc = model.accuracy(X_val, y_val)\n",
        "\n",
        "    if (val_acc > best_acc):\n",
        "        best_c = c\n",
        "        best_acc = val_acc\n",
        "\n",
        "    print(f\"c = {c},\\tval_acc = {val_acc}\")\n",
        "\n",
        "print(f\"Validation, best c = {best_c}, acc = {best_acc}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QbS0NSbGhMVV"
      },
      "source": [
        "### Report the accuracy on the test set for the selected classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io-Kf_0q0xGK"
      },
      "source": [
        "Since there are multiple c values with the highest accuracy of 0.86,\n",
        "we will arbitrarily pick the smallest c value of $c=1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A_9md8Jhozg",
        "outputId": "a9c0caa3-6917-4e0f-ca74-93fca42c4794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set\n",
            "c = 1,\ttest acc = 0.8305084745762712\n"
          ]
        }
      ],
      "source": [
        "best_c = 1\n",
        "model = LinearSlackSVM()\n",
        "model.fit(X_train, y_train, best_c)\n",
        "test_acc = model.accuracy(X_test, y_test)\n",
        "\n",
        "print(\"Test Set\")\n",
        "print(f\"c = {best_c},\\ttest acc = {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHIPft8chvpQ"
      },
      "source": [
        "## 2. Dual SVMs with Gaussian Kernels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0chqHpj1qmC"
      },
      "source": [
        "Dual Formulation with slack\n",
        "\n",
        "$$\\min_{\\lambda \\geq 0} \\frac{1}{2} \\sum_i \\sum_j \\lambda_i \\lambda_j y_i y_j k(x^{(i)}, x^{(j)}) - \\sum_i \\lambda_i$$\n",
        "subject to\n",
        "$$ \\sum_i \\lambda_i y_i = 0 $$\n",
        "$$ c \\geq \\lambda_i \\geq 0 \\forall i$$\n",
        "\n",
        "CVXOPT Formulation\n",
        "$$\\min \\frac{1}{2} z^T P z + q^T z $$\n",
        "subject to\n",
        "$$ Gz \\leq h $$\n",
        "$$ Az = b $$\n",
        "\n",
        "Let $z = [\\lambda_1, ..., \\lambda_m]$\n",
        "\n",
        "---\n",
        "\n",
        "Objective Function\n",
        "\n",
        "Therefore we must represent $P$ as a matrix of $\\sum_i \\sum_j y_i y_j k(x^{(i)}, x^{(j)}) $\n",
        "$$ P_{i,j} = y_i y_j k(x^{(i)}, x^{(j)}) $$\n",
        "\n",
        "$q^T z$ would represent $- \\sum_i \\lambda_i$\n",
        "$$ q = [-1,...,-1] $$\n",
        "\n",
        "---\n",
        "\n",
        "Inequality Constraint\n",
        "\n",
        "$c \\geq \\lambda_i \\geq 0$ can be decomposed into two inequalities\n",
        "$$ \\lambda_i \\geq 0 = -\\lambda_i \\leq 0 $$\n",
        "$$ \\lambda_i \\leq c $$\n",
        "\n",
        "Therefore $G$ is a negative identity matrix for the upper half and a regular identify matrix on the lower half.\n",
        "\n",
        "$h$ would be a 0 vector for the first $m$ terms and a vector of c's for the next $m$ terms\n",
        "\n",
        "---\n",
        "\n",
        "Equality Constraint\n",
        "\n",
        "The equality constrain would represent $ \\sum_i \\lambda_i y_i = 0 $\n",
        "\n",
        "$$ A = y $$\n",
        "$$ b = 0 $$\n",
        "\n",
        "---\n",
        "\n",
        "Calculating the bias\n",
        "\n",
        "From complementary slackness, we know $\\sum_i \\lambda_i^* f_i(x^*) = 0$ and $\\nu_i^* \\xi_i^* = 0$ or in other words:\n",
        "\n",
        "$$\\lambda_i (1 - y_i(w^T x_i + b) - \\xi_i) = 0$$ \n",
        "\n",
        "If $\\lambda_i$ is non-zero this implies $\\xi_i = 0$ such that:\n",
        "\n",
        "$$ 1 - y_i(w^T x_i + b) = 0$$ \n",
        "$$ b = y_i - w^Tx_i$$\n",
        "\n",
        "For any data point in training with non-zero lambdas, we can calculate the bias. In implementation, we can take the \n",
        "average over all lambdas over a certain threshold to account for numerical inaccuracies. In this implementation, we \n",
        "will be using a threshold of $0$.\n",
        "\n",
        "---\n",
        "\n",
        "Calculating the prediction\n",
        "\n",
        "When using a feature transformation, $w^Tx$ will become $w^T\\phi(x)$. When using a Gaussian kernel, we can not directly compute\n",
        "$\\phi(x)$. We can directly compute $w^T\\phi(x)$. We notice the lagrangian is minimized when\n",
        "\n",
        "$$ w = \\sum_i \\lambda_i y_i \\phi(x_i)$$\n",
        "\n",
        "Therefore we can compute $w^Tx$ in a similar manner:\n",
        "\n",
        "$$ w^T\\phi(x) = \\sum_i \\lambda_i y_i \\phi(x_i)^T \\phi(x) = \\sum_i \\lambda_i y_i k(x_i, x)$$\n",
        "\n",
        "In implementation we can optimize the summation by discarding data points whose lambdas is 0 or near zero under some theshold.\n",
        "In this implementation, we will be using a threshold of $0$."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Amcl_7l5h32L"
      },
      "source": [
        "### Apply the SVM formulation for each choice of $c \\in \\{10^{-4}, 10^{-3}, ..., 10^3, 10^4\\}$ without using any feature maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spTThcW62g9S"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GaussianSVM():\n",
        "    def __init__(self, zero_threshold=0):\n",
        "        self.zero_threshold = zero_threshold  # Controls what lambda values are considered 0\n",
        "        self.lambdas = None\n",
        "        self.sv = None  # Saved X values\n",
        "        self.sv_y = None  # Saved y values\n",
        "        self.b = None\n",
        "        self.sigma2 = None # sigma squared\n",
        "\n",
        "    def __gaussian_kernel(self, x, y, sigma2):\n",
        "        return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma2)))\n",
        "    \n",
        "    def fit(self, X, y, c, sigma2):\n",
        "\n",
        "        num_data = X.shape[0]\n",
        "\n",
        "\n",
        "        # K matrix to save the kernel results\n",
        "        K = np.zeros((num_data, num_data))\n",
        "        for i in range(num_data):\n",
        "            for j in range(num_data):\n",
        "                K[i, j] = self.__gaussian_kernel(X[i], X[j], sigma2) \n",
        "\n",
        "        P = np.outer(y, y) * K\n",
        "\n",
        "        q = np.ones(num_data) * -1\n",
        "\n",
        "        G_top = np.identity(num_data) * -1\n",
        "        G_bot = np.identity(num_data)\n",
        "        G = np.vstack((G_top, G_bot))\n",
        "\n",
        "        h = np.append(np.zeros(num_data), np.ones(num_data) * c)\n",
        "\n",
        "        A = y.reshape(1, -1)\n",
        "\n",
        "        b = 0.0\n",
        "\n",
        "        P = cvxopt.matrix(P)\n",
        "        q = cvxopt.matrix(q)\n",
        "        G = cvxopt.matrix(G)\n",
        "        h = cvxopt.matrix(h)\n",
        "        A = cvxopt.matrix(A)\n",
        "        b = cvxopt.matrix(b)\n",
        "        \n",
        "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "        \n",
        "        lambdas = np.ravel(solution['x'])\n",
        "\n",
        "        sv = lambdas > self.zero_threshold  # support vectors\n",
        "        ind = np.arange(len(lambdas))[sv]   # indices of support vectors\n",
        "\n",
        "        self.lambdas = lambdas[sv]\n",
        "        self.sv = X[sv]\n",
        "        self.sv_y = y[sv]\n",
        "        self.sigma2 = sigma2\n",
        "\n",
        "        self.b = 0\n",
        "        for i in range(len(self.lambdas)):\n",
        "            self.b += self.sv_y[i]\n",
        "            self.b -= np.sum(self.lambdas * self.sv_y * K[ind[i],sv])\n",
        "        self.b /= len(self.lambdas)\n",
        "    \n",
        "    def predict_one(self, x):\n",
        "        k = np.zeros(len(self.sv))\n",
        "        for i, point in enumerate(self.sv):\n",
        "            k[i] = self.__gaussian_kernel(x, point, self.sigma2)\n",
        "        return np.sum(self.lambdas * self.sv_y * k) + self.b\n",
        "    \n",
        "    def predict(self, X):\n",
        "        y_pred = [self.predict_one(x) for x in X]\n",
        "        return np.sign(np.array(y_pred))\n",
        "    \n",
        "    def accuracy(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        correct = np.equal(y, y_pred)\n",
        "        return np.count_nonzero(correct) / len(y)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5LV2KiJtiavI"
      },
      "source": [
        "### What is the accuracy on the training set for each pair of $c$ and $\\sigma^2$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFLgA_a6iiAO",
        "outputId": "a8843095-98ef-4b9f-dd10-c1ad272a33d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c = 0.001, sigma2 = 0.01     \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.001, sigma2 = 0.1      \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.001, sigma2 = 1.0      \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.001, sigma2 = 10.0     \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.001, sigma2 = 100.0    \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.001, sigma2 = 1000.0   \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.001, sigma2 = 10000.0  \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 0.01     \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 0.1      \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 1.0      \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 10.0     \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 100.0    \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 1000.0   \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.01, sigma2 = 10000.0  \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 0.01     \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 0.1      \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 1.0      \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 10.0     \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 100.0    \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 1000.0   \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 0.1, sigma2 = 10000.0  \ttrain acc = 0.782051282051282 \tval_acc = 0.7413793103448276\n",
            "c = 1.0, sigma2 = 0.01     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1.0, sigma2 = 0.1      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1.0, sigma2 = 1.0      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1.0, sigma2 = 10.0     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1.0, sigma2 = 100.0    \ttrain acc = 0.9358974358974359\tval_acc = 0.8275862068965517\n",
            "c = 1.0, sigma2 = 1000.0   \ttrain acc = 0.8717948717948718\tval_acc = 0.7758620689655172\n",
            "c = 1.0, sigma2 = 10000.0  \ttrain acc = 0.8717948717948718\tval_acc = 0.7931034482758621\n",
            "c = 10.0, sigma2 = 0.01     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10.0, sigma2 = 0.1      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10.0, sigma2 = 1.0      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10.0, sigma2 = 10.0     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10.0, sigma2 = 100.0    \ttrain acc = 0.9743589743589743\tval_acc = 0.7931034482758621\n",
            "c = 10.0, sigma2 = 1000.0   \ttrain acc = 0.9358974358974359\tval_acc = 0.8103448275862069\n",
            "c = 10.0, sigma2 = 10000.0  \ttrain acc = 0.8717948717948718\tval_acc = 0.7931034482758621\n",
            "c = 100.0, sigma2 = 0.01     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100.0, sigma2 = 0.1      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100.0, sigma2 = 1.0      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100.0, sigma2 = 10.0     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100.0, sigma2 = 100.0    \ttrain acc = 1.0               \tval_acc = 0.7931034482758621\n",
            "c = 100.0, sigma2 = 1000.0   \ttrain acc = 0.9615384615384616\tval_acc = 0.7241379310344828\n",
            "c = 100.0, sigma2 = 10000.0  \ttrain acc = 0.8974358974358975\tval_acc = 0.7931034482758621\n",
            "c = 1000.0, sigma2 = 0.01     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1000.0, sigma2 = 0.1      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1000.0, sigma2 = 1.0      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1000.0, sigma2 = 10.0     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 1000.0, sigma2 = 100.0    \ttrain acc = 1.0               \tval_acc = 0.7931034482758621\n",
            "c = 1000.0, sigma2 = 1000.0   \ttrain acc = 0.6538461538461539\tval_acc = 0.6551724137931034\n",
            "c = 1000.0, sigma2 = 10000.0  \ttrain acc = 0.9615384615384616\tval_acc = 0.8103448275862069\n",
            "c = 10000.0, sigma2 = 0.01     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10000.0, sigma2 = 0.1      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10000.0, sigma2 = 1.0      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10000.0, sigma2 = 10.0     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 10000.0, sigma2 = 100.0    \ttrain acc = 1.0               \tval_acc = 0.7931034482758621\n",
            "c = 10000.0, sigma2 = 1000.0   \ttrain acc = 0.6538461538461539\tval_acc = 0.6551724137931034\n",
            "c = 10000.0, sigma2 = 10000.0  \ttrain acc = 0.6923076923076923\tval_acc = 0.6724137931034483\n",
            "c = 100000.0, sigma2 = 0.01     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100000.0, sigma2 = 0.1      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100000.0, sigma2 = 1.0      \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100000.0, sigma2 = 10.0     \ttrain acc = 1.0               \tval_acc = 0.7413793103448276\n",
            "c = 100000.0, sigma2 = 100.0    \ttrain acc = 1.0               \tval_acc = 0.7931034482758621\n",
            "c = 100000.0, sigma2 = 1000.0   \ttrain acc = 0.6538461538461539\tval_acc = 0.6551724137931034\n",
            "c = 100000.0, sigma2 = 10000.0  \ttrain acc = 0.6410256410256411\tval_acc = 0.6206896551724138\n"
          ]
        }
      ],
      "source": [
        "c_values = [10e-4, 10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3, 10e4]\n",
        "sigma2_values = [10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3]\n",
        "\n",
        "X_train = park_train[:,1:]\n",
        "y_train = park_train[:,0]\n",
        "y_train[y_train == 0] = -1\n",
        "\n",
        "X_val = park_val[:,1:]\n",
        "y_val = park_val[:,0]\n",
        "y_val[y_val == 0] = -1\n",
        "\n",
        "X_test = park_test[:,1:]\n",
        "y_test = park_test[:,0]\n",
        "y_test[y_test == 0] = -1\n",
        "\n",
        "best_train_param = []\n",
        "best_train_acc = 0\n",
        "\n",
        "best_val_param = []\n",
        "best_val_acc = 0\n",
        "\n",
        "model = GaussianSVM()\n",
        "\n",
        "for c in c_values:\n",
        "    for sigma2 in sigma2_values:\n",
        "        model.fit(X_train, y_train, c, sigma2)\n",
        "        train_acc = model.accuracy(X_train, y_train)\n",
        "        val_acc = model.accuracy(X_val, y_val)\n",
        "\n",
        "        if (train_acc > best_train_acc):\n",
        "            best_train_acc = train_acc\n",
        "            best_train_param = [(c, sigma2)]\n",
        "        elif (train_acc == best_train_acc):\n",
        "            best_train_param.append((c, sigma2))\n",
        "\n",
        "        if (val_acc > best_val_acc):\n",
        "            best_val_acc = val_acc\n",
        "            best_val_param = [(c, sigma2)]\n",
        "        elif (val_acc == best_val_acc):\n",
        "            best_val_param.append((c, sigma2))\n",
        "\n",
        "\n",
        "        print(f\"c = {c}, sigma2 = {sigma2:<8} \\ttrain acc = {train_acc:<18}\\tval_acc = {val_acc}\")\n",
        "\n",
        "# print(f\"Best training accuracy: {best_train_acc} with {best_train_param}\")\n",
        "# print(f\"Best validation accuracy: {best_val_acc} with {best_val_param}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LFvzJPYSiivF"
      },
      "source": [
        "### Use the validation set to select the best value of $c$ and $\\sigma^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3jP5-BkiaYm",
        "outputId": "abc016af-4906-4e8f-85cc-e297b637f2d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best validation accuracy: 0.8620689655172413\n",
            "c = 1000.0 and sigma^2 = 10000.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best validation accuracy: {best_val_acc}\")\n",
        "\n",
        "for param in best_val_param:\n",
        "  print(f\"c = {param[0]} and sigma^2 = {param[1]}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VarOw98eirAY"
      },
      "source": [
        "### Report the accuracy on the test set for the selected classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc66t5h_i0vm",
        "outputId": "8d3db08c-1882-4639-d4b5-d9e49ac5130a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test accuracy: 0.7288135593220338 with c = 1000.0 and sigma^2 = 10000.0\n"
          ]
        }
      ],
      "source": [
        "model = GaussianSVM()\n",
        "\n",
        "c = best_val_param[0][0]\n",
        "sig = best_val_param[0][1]\n",
        "model.fit(X_train, y_train, c, sig)\n",
        "test_acc = model.accuracy(X_test, y_test)\n",
        "\n",
        "print(f\"test accuracy: {test_acc} with c = {c} and sigma^2 = {sig}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BMAvYJOrf_k3"
      },
      "source": [
        "# Problem 2: Method of Lagrange Multipliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GSjJqP4jhH0"
      },
      "source": [
        "Suppose that we modified the objective function in the SVM with slack formulation to be a quadratic\n",
        "penalty instead of a linear penalty, that is minimize $\\frac{1}{2}\\Vert w\\Vert^2 +c\\sum_i \\xi_i^2$ subject to the same constraints as the standard SVM with slack. What is the dual of this new quadratic penalized SVM with slack problem for a fixed c? Can the kernel trick still be applied?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD5LwvCQ6MZP"
      },
      "source": [
        "Primal problem\n",
        "\n",
        "$$\\frac{1}{2} ||w||^2 + c \\sum_i \\xi_i^2$$\n",
        "\n",
        "subject to\n",
        "\n",
        "$$y_i(w^T x^{(i)} + b) \\geq 1 - \\xi_i$$\n",
        "\n",
        "Unlike the original problem, we can discard $\\xi_i \\geq 0$ because $\\xi^2$ will\n",
        "always be positive.\n",
        "\n",
        "---\n",
        "\n",
        "Lagrangian Formulation\n",
        "\n",
        "$$L(w, b, \\xi, \\lambda) = \\frac{1}{2} w^T w + c \\sum_i \\xi_i^2\n",
        "  + \\sum_i \\lambda_i (1 - \\xi_i - y_i (w^T x^{(i)} + b))$$\n",
        "\n",
        "We get the dual formulation when we minimize the primal variables. Since, $c \\sum_i \\xi_i^2$ is convex, the Lagrangian still remains a convex problem and the min can be found by taking the first order partial derivative and setting them equal to 1.\n",
        "\n",
        "$$\\min_{w,b,\\xi} L(w, b, \\xi, \\lambda)$$\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w} = w + \\sum_i \\lambda_i y_i x^{(i)} = 0$$\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial b} = \\sum_i -\\lambda_i y_i = 0$$\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial \\xi_i} = 2 c \\xi_i - \\lambda_i = 0$$\n",
        "\n",
        "\n",
        "Similar to the non-squared variation, we can now subsitute $w = -\\sum_i \\lambda_i y_i x^{(i)}$ and $\\sum_i -\\lambda_i y_i = 0$ to derive:\n",
        "\n",
        "$$-\\frac{1}{2} \\sum_{i,j} \\lambda_i \\lambda_j y_i y_j (x^{(i)})^T x^{(j)}\n",
        "  + c \\sum_i \\xi^2 + \\sum_i \\lambda_i - \\sum_i \\lambda_i \\xi_i$$\n",
        "\n",
        "Subsituting $\\xi = \\frac{\\lambda_i}{2c}$\n",
        "\n",
        "$$ g(\\lambda) = -\\frac{1}{2} \\sum_{i, j} \\lambda_i \\lambda_j y_i y_j \n",
        "   (x^{(i)})^T x^{(j)} - \\frac{1}{4c} \\sum_i \\lambda_i^2 + \\sum_i \\lambda_i$$\n",
        "\n",
        "Dual formulation\n",
        "\n",
        "$$\\min_\\lambda g(\\lambda)$$\n",
        "\n",
        "subject to \n",
        "\n",
        "$$ \\sum_i y_i \\lambda_i = 0$$\n",
        "$$ \\lambda_i \\geq 0$$\n",
        "\n",
        "Since the dual formulation contains the term $(x^{(i)})^T x^{(j)}$, we can apply the kernel trick here as well by subtituting it with a kernel function, \n",
        "$k(x^{(i)}, x^{(j)})$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ywALwgmpgBS1"
      },
      "source": [
        "# Problem 3: Poisonous Mushrooms?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TevsQueIkzrk"
      },
      "source": [
        "## 1. Report the maximum information gain for each node that you added to the tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgs5jxgkj3Y8",
        "outputId": "e90a5f72-b1f3-477e-c202-a8dda9c9db42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split on index: 5 with IG:0.9078035498174334\n",
            "\tâ”œâ”€â”€Attr: b'l' => b'e'\n",
            "\tâ”œâ”€â”€Attr: b'm' => b'p'\n",
            "\tâ”œâ”€â”€Attr: b'p' => b'p'\n",
            "\tâ”œâ”€â”€Attr: b'a' => b'e'\n",
            "\tâ”œâ”€â”€Attr: b'c' => b'p'\n",
            "\tâ”œâ”€â”€Attr: b'f' => b'p'\n",
            "\tâ”œâ”€â”€Attr: b'y' => b'p'\n",
            "\tâ”œâ”€â”€Attr: b'n' => Split on index: 20 with IG:0.13971500736229386\n",
            "\t\tâ”œâ”€â”€Attr: b'k' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'n' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'y' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'h' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'b' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'o' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'w' => Split on index: 22 with IG:0.2650444336226324\n",
            "\t\t\tâ”œâ”€â”€Attr: b'l' => Split on index: 3 with IG:0.8390040613676977\n",
            "\t\t\t\tâ”œâ”€â”€Attr: b'c' => b'e'\n",
            "\t\t\t\tâ”œâ”€â”€Attr: b'w' => b'p'\n",
            "\t\t\t\tâ”œâ”€â”€Attr: b'y' => b'p'\n",
            "\t\t\t\tâ”œâ”€â”€Attr: b'n' => b'e'\n",
            "\t\t\tâ”œâ”€â”€Attr: b'p' => b'e'\n",
            "\t\t\tâ”œâ”€â”€Attr: b'd' => Split on index: 8 with IG:0.7553754125614287\n",
            "\t\t\t\tâ”œâ”€â”€Attr: b'b' => b'e'\n",
            "\t\t\t\tâ”œâ”€â”€Attr: b'n' => b'p'\n",
            "\t\t\tâ”œâ”€â”€Attr: b'w' => b'e'\n",
            "\t\t\tâ”œâ”€â”€Attr: b'g' => b'e'\n",
            "\t\tâ”œâ”€â”€Attr: b'r' => b'p'\n",
            "\tâ”œâ”€â”€Attr: b's' => b'p'\n"
          ]
        }
      ],
      "source": [
        "class DecisionTree():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.root = None\n",
        "  \n",
        "  def get_ig(self, data, i):\n",
        "      num_data = len(data)\n",
        "      attr_values = set(data[:,i])\n",
        "      result = 0\n",
        "\n",
        "      # Caluclate H(Y)\n",
        "      for label in set(data[:,0]):\n",
        "          num_label = sum(data[:, 0] == label)\n",
        "          prob_label = num_label / num_data\n",
        "          result -= prob_label * math.log2(prob_label)\n",
        "\n",
        "      # Calculate H(Y|X)\n",
        "      for attr in attr_values:\n",
        "          data_given_attr = data[data[:,i] == attr]\n",
        "          num_given_attr = len(data_given_attr)\n",
        "          curr_term = 0\n",
        "\n",
        "          label_values = set(data_given_attr[:, 0])\n",
        "          for label in label_values:\n",
        "              num_label_given_attr = sum(data_given_attr[:, 0] == label)\n",
        "              prob_label_given_attr = num_label_given_attr / num_given_attr\n",
        "              log_prob = math.log2(prob_label_given_attr) #if prob_label_given_attr > 0 else 0 \n",
        "              curr_term += prob_label_given_attr * log_prob\n",
        "\n",
        "          result += (num_given_attr / num_data) * curr_term\n",
        "      return result\n",
        "    \n",
        "  def get_max_ig(self, data):\n",
        "    index = -1\n",
        "    max_ig = 0\n",
        "    for i in range(1, len(data[0])):\n",
        "        ig = self.get_ig(data, i)\n",
        "        if (ig > max_ig): # strict greater ensure the left most one gets picked first\n",
        "            max_ig = ig\n",
        "            index = i\n",
        "    return (index, max_ig)\n",
        "\n",
        "  def fit(self, data):\n",
        "    index, ig = self.get_max_ig(data)\n",
        "    root = self.Node(attr_index=index, ig=ig)\n",
        "\n",
        "    # leaf node, stop when only one class or all attr are exhausted\n",
        "    if (index == -1):\n",
        "        root.answer = Counter(data[:,0]).most_common(1)[0][0]\n",
        "        return root\n",
        "\n",
        "    # explore children\n",
        "    children = dict()\n",
        "    for attr in set(data[:,index]):\n",
        "        children.update({attr : self.fit(data[data[:, index] == attr])})\n",
        "    root.children = children\n",
        "\n",
        "    self.root = root\n",
        "\n",
        "    return root\n",
        "\n",
        "  def print_tree(self):\n",
        "    return self.__print_tree(root=self.root)\n",
        "  \n",
        "  def __print_tree(self, root, prefix=\"â”œâ”€â”€\"):\n",
        "    if root.answer is not None:\n",
        "        print(f\"{root.answer}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Split on index: {root.attr_index} with IG:{root.ig}\")\n",
        "    \n",
        "    for attr, child in root.children.items():\n",
        "        print(f\"\\t{prefix}Attr: {attr} => \", end=\"\")\n",
        "        self.__print_tree(child, \"\\t\"+ prefix )\n",
        "    return\n",
        "\n",
        "  def predict(self, root, data):\n",
        "    if root.answer is not None:\n",
        "        return root.answer\n",
        "    return self.predict(root.children[data[root.attr_index]], data)\n",
        "\n",
        "  def accuracy(self, data):\n",
        "    num_data = len(data)\n",
        "    correct = 0\n",
        "    for point in data:\n",
        "        if (point[0] == self.predict(self.root, point)):\n",
        "            correct += 1\n",
        "    \n",
        "    return correct / num_data\n",
        "\n",
        "  class Node():\n",
        "    def __init__(self, attr_index=None, ig=0):\n",
        "        self.ig = ig\n",
        "        self.attr_index = attr_index\n",
        "        self.children = None\n",
        "        self.answer = None\n",
        "\n",
        "\n",
        "model = DecisionTree()\n",
        "model.fit(mush_train)\n",
        "model.print_tree()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hps1nhRZWbfL"
      },
      "source": [
        "Attr: x represents which values are being split on. If the RHS of => is e/p, then that node is a leaf, else it will continue splitting on a new index until all indicies are exhuasted or the leaf contains only one label. Indicies starts at $i=1$ for the first attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1BF54yinTni"
      },
      "source": [
        "## 2. What is the accuracy of this decision tree on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqGWpAugnif8",
        "outputId": "cceb3f83-44c6-4797-e784-490a46062f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test accuracy: {model.accuracy(mush_test)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_MFc5JvygCaA"
      },
      "source": [
        "# Problem 4: Cross-Validation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0Znq7eFykCXL"
      },
      "source": [
        "Apply 10-fold cross validation to fit an SVM with slack classifier (no feature maps) to the data\n",
        "set wdbc train.data (each row corresponds to a single data observation and the class label +1/-1 is\n",
        "the first entry in each row)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtDZPfCQf7O2",
        "outputId": "08a92255-aa8e-4479-f30f-652739658c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c: 0.001, \t average acc: 0.85\n",
            "c: 0.01, \t average acc: 0.8633333333333335\n",
            "c: 0.1, \t average acc: 0.8666666666666668\n",
            "c: 1.0, \t average acc: 0.8800000000000001\n",
            "c: 10.0, \t average acc: 0.8866666666666667\n",
            "c: 100.0, \t average acc: 0.9166666666666667\n",
            "c: 1000.0, \t average acc: 0.9166666666666667\n",
            "c: 10000.0, \t average acc: 0.9066666666666668\n",
            "c: 100000.0, \t average acc: 0.9066666666666668\n",
            "Best c : 100.0 with acc: 0.9166666666666667\n",
            "Testing accuracy: 0.9864864864864865\n"
          ]
        }
      ],
      "source": [
        "# Since there are multiple c values that have the highest accuracy\n",
        "# we will arbitrarily pick the lowest c with the highest acc\n",
        "\n",
        "# Split training data into 10 folds\n",
        "folds = np.split(wdbc_train, 10)\n",
        "best_c = 0\n",
        "best_acc = 0\n",
        "\n",
        "# Find best c\n",
        "c_values = [10e-4, 10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3, 10e4]\n",
        "for c in c_values:\n",
        "    avg_acc = 0\n",
        "    for i in range(len(folds)):\n",
        "        data = [x for j, x in enumerate(folds) if j != i] \n",
        "        data = np.concatenate(data)\n",
        "        X_train = data[:, 1:]\n",
        "        y_train = data[:, 0]\n",
        "        X_val = folds[i][:,1:]\n",
        "        y_val = folds[i][:, 0]\n",
        "        model = LinearSlackSVM()\n",
        "        model.fit(X_train, y_train, c)\n",
        "        val_acc = model.accuracy(X_val, y_val)\n",
        "        #print(f\"Fold {i}: acc = {val_acc}\")\n",
        "        avg_acc += val_acc\n",
        "    avg_acc /= len(folds)\n",
        "    if avg_acc > best_acc:\n",
        "      best_c = c\n",
        "      best_acc = avg_acc\n",
        "    print(f\"c: {c}, \\t average acc: {avg_acc}\")\n",
        "\n",
        "print(f\"Best c : {best_c} with acc: {best_acc}\")\n",
        "\n",
        "# Retrain on all training data\n",
        "X_train = wdbc_train[:,1:]\n",
        "y_train = wdbc_train[:,0]\n",
        "\n",
        "model = LinearSlackSVM()\n",
        "model.fit(X_train, y_train, best_c)\n",
        "\n",
        "# Test on testing set\n",
        "X_test = wdbc_test[:, 1:]\n",
        "y_test = wdbc_test[:, 0]\n",
        "test_acc = model.accuracy(X_test, y_test)\n",
        "\n",
        "print(f\"Testing accuracy: {test_acc}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:51:29) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "eee0ec1dfc014c5e818c9fd6187bf3227a654b7ffe32fcac85496f478f59351d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
